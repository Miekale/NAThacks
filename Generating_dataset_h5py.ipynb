{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T02:10:10.820505600Z",
     "start_time": "2024-01-01T02:10:06.670908300Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pyedflib\n",
    "from pyedflib import highlevel\n",
    "import os\n",
    "import h5py\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T00:31:27.962974500Z",
     "start_time": "2024-01-01T00:31:27.937860200Z"
    }
   },
   "outputs": [],
   "source": [
    "#Constants \n",
    "dataPath = r\"C:\\Users\\markd\\Documents\\GitHub\\NAThacks\\data\\files\"\n",
    "h5Path = r\"h5py/val.h5\"\n",
    "numChannels = 64\n",
    "labels = {\n",
    "    \"T0\" : \"rest\",\n",
    "    \"T1\" : [\"leftHand\", \"bothHands\"],\n",
    "    \"T2\" : [\"rightHand\", \"bothFeet\"]\n",
    "}\n",
    "labelsDict = {\n",
    "    \"rest\": 0,\n",
    "    \"leftHand\": 1,\n",
    "    \"rightHand\": 2,\n",
    "    \"bothHands\": 3,\n",
    "    \"bothFeet\": 4\n",
    "}\n",
    "frequency = 160\n",
    "time_period = 640\n",
    "prc_overlap = .90\n",
    "chunk_size = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T00:31:37.178417100Z",
     "start_time": "2024-01-01T00:31:37.161407300Z"
    }
   },
   "outputs": [],
   "source": [
    "rest = []\n",
    "leftHand = []\n",
    "rightHand = []\n",
    "bothHands = []\n",
    "bothFeet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(h5Path, \"w\") as specs:\n",
    "    specs.create_dataset(\"rest\",(chunk_size,81,31,64), maxshape=(None,81,31,64),compression=\"gzip\")\n",
    "    specs.create_dataset(\"leftHand\",(chunk_size,81,31,64), maxshape=(None,81,31,64), compression=\"gzip\")\n",
    "    specs.create_dataset(\"rightHand\",(chunk_size,81,31,64), maxshape=(None,81,31,64), compression=\"gzip\")\n",
    "    specs.create_dataset(\"bothHands\",(chunk_size,81,31,64), maxshape=(None,81,31,64), compression=\"gzip\")\n",
    "    specs.create_dataset(\"bothFeet\",(chunk_size,81,31,64), maxshape=(None,81,31,64), compression=\"gzip\")\n",
    "\n",
    "def storeData(data, dataset : str, size):\n",
    "    with h5py.File(h5Path, \"r+\") as f:\n",
    "        df = f[dataset]\n",
    "        current_shape = df.shape\n",
    "        df.resize((current_shape[0] + size, 81, 31, 64))\n",
    "        df[current_shape[0]:, :] = data\n",
    "        print(f\"{dataset} adjusted to {current_shape[0] + size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "with h5py.File(h5Path, \"w\") as specs:\n",
    "    specs.create_dataset(\"Samples\",(chunk_size,81,31,64), maxshape=(None,81,31,64),compression=\"gzip\")\n",
    "    specs.create_dataset(\"Classes\",(chunk_size,5), maxshape=(None,5),compression=\"gzip\")\n",
    "\n",
    "def storeDataSingle(data, dataset : str, size):\n",
    "    with h5py.File(h5Path, \"r+\") as f:\n",
    "        df = f['Samples']\n",
    "        current_shape = df.shape\n",
    "        df.resize((current_shape[0] + size, 81, 31, 64))\n",
    "        df[current_shape[0]:, :] = data\n",
    "        print(f\"Samples adjusted to {current_shape[0] + size}\")\n",
    "        \n",
    "        # Store class label\n",
    "        # Classes need to be one-hot encoded\n",
    "        class_idx = labelsDict[dataset]\n",
    "        label = np.zeros([size, 5])\n",
    "        label[:,class_idx] = 1\n",
    "        \n",
    "        labels = f['Classes']\n",
    "        current_shape = labels.shape\n",
    "        labels.resize((current_shape[0] + size, 5))\n",
    "        labels[current_shape[0]:, :] = label  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T00:32:01.231062500Z",
     "start_time": "2024-01-01T00:32:01.209007100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T00:33:00.504584200Z",
     "start_time": "2024-01-01T00:32:06.489635100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person 1 completed\n",
      "person 2 completed\n",
      "person 3 completed\n",
      "person 4 completed\n",
      "person 5 completed\n",
      "person 6 completed\n",
      "person 7 completed\n",
      "person 8 completed\n",
      "person 9 completed\n",
      "person 10 completed\n",
      "person 11 completed\n",
      "person 12 completed\n",
      "person 13 completed\n"
     ]
    }
   ],
   "source": [
    "#Generating spectograms Images\n",
    "person = 1\n",
    "for folder in os.listdir(dataPath)[90:]:\n",
    "    for fileName in os.listdir(os.path.join(dataPath,folder)):\n",
    "\n",
    "        #Skipping files .event files\n",
    "        if fileName.find(\"event\") != -1:\n",
    "            continue\n",
    "\n",
    "        #reading EDF file and extracting data\n",
    "        filePath = os.path.join(dataPath,folder,fileName)\n",
    "        annotations = \"\"\n",
    "        file = \"\"\n",
    "\n",
    "        #Getting the annotations and Data\n",
    "        file = pyedflib.EdfReader(filePath)\n",
    "        annotations = file.readAnnotations()\n",
    "        file.close()\n",
    "\n",
    "        signals, signal_headers, header = highlevel.read_edf(filePath)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        #Looping through the various \n",
    "        for i, period in enumerate(annotations[0]):\n",
    "            #Getting signal data for 4 second period\n",
    "            data = signals[:,int(annotations[0][i]):int(annotations[0][i]+time_period)]\n",
    "\n",
    "            f, t, image = signal.spectrogram(data,frequency, nperseg = frequency, noverlap = frequency * prc_overlap)\n",
    "            image = np.transpose(image,(1,2,0))\n",
    "\n",
    "            #Assigning label to file\n",
    "            label = annotations[2][i]\n",
    "\n",
    "            #Categories of the different tests\n",
    "            leftOrRight = [\"03\",\"04\",\"07\",\"08\",\"11\",\"12\"]\n",
    "            if label == \"T1\":\n",
    "                if any(x == fileName[5:7] for x in leftOrRight):\n",
    "                    leftHand.append(image)\n",
    "                    if len(leftHand) == chunk_size:\n",
    "                        storeDataSingle(leftHand,\"leftHand\", chunk_size)\n",
    "                        leftHand = []\n",
    "                else: \n",
    "                    bothHands.append(image)\n",
    "                    if len(bothHands) == chunk_size:\n",
    "                        storeDataSingle(bothHands,\"bothHands\", chunk_size)\n",
    "                        bothHands = []\n",
    "            elif label == \"T2\":\n",
    "                if any(x == fileName[5:7] for x in leftOrRight):\n",
    "                    rightHand.append(image)\n",
    "                    if len(rightHand) == chunk_size:\n",
    "                        storeDataSingle(rightHand,\"rightHand\", chunk_size)\n",
    "                        rightHand = []\n",
    "                else:\n",
    "                    bothFeet.append(image)\n",
    "                    if len(bothFeet) == chunk_size:\n",
    "                        storeDataSingle(bothFeet,\"bothFeet\", chunk_size)\n",
    "                        bothFeet = []\n",
    "            else:\n",
    "                rest.append(image)\n",
    "                if len(rest) == chunk_size:\n",
    "                        storeDataSingle(rest,\"rest\", chunk_size)\n",
    "                        rest = []\n",
    "            count += 1\n",
    "    print(f\"person {person} completed\")\n",
    "    person +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T00:35:02.518056400Z",
     "start_time": "2024-01-01T00:33:00.543476400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples adjusted to 4856\n",
      "Samples adjusted to 5435\n",
      "Samples adjusted to 6020\n",
      "Samples adjusted to 6605\n",
      "Samples adjusted to 7185\n"
     ]
    }
   ],
   "source": [
    "storeDataSingle(rest,\"rest\", len(rest))\n",
    "rest = []\n",
    "storeDataSingle(bothFeet,\"bothFeet\", len(bothFeet))\n",
    "bothFeet = []\n",
    "storeDataSingle(leftHand,\"leftHand\", len(leftHand))\n",
    "leftHand = []\n",
    "storeDataSingle(rightHand, \"rightHand\",len(rightHand))\n",
    "rightHand = []\n",
    "storeDataSingle(bothHands,\"bothHands\",len(bothHands))\n",
    "bothHands = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4000, dtype=torch.float64)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([4,1,2,4,2])\n",
    "b = torch.tensor([4,1,3,3,3])\n",
    "torch.sum(a == b).double() / len(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T02:11:21.249739200Z",
     "start_time": "2024-01-01T02:11:21.215725500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nathacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
