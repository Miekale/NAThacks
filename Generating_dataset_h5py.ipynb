{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:35:36.687510Z",
     "start_time": "2024-01-02T18:35:36.584983200Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pyedflib\n",
    "from pyedflib import highlevel\n",
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:35:36.742517600Z",
     "start_time": "2024-01-02T18:35:36.599983300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Constants \n",
    "dataPath = r\"C:\\Users\\Humperdink2\\Documents\\github\\NAThacks\\Data\\files\"\n",
    "h5Path = r\"h5py/1personval2.h5\"\n",
    "numChannels = 64\n",
    "labels = {\n",
    "    \"T0\" : \"rest\",\n",
    "    \"T1\" : [\"leftHand\", \"bothHands\"],\n",
    "    \"T2\" : [\"rightHand\", \"bothFeet\"]\n",
    "}\n",
    "labelsDict = {\n",
    "    \"rest\": 0,\n",
    "    \"leftHand\": 1,\n",
    "    \"rightHand\": 2,\n",
    "    \"bothHands\": 3,\n",
    "    \"bothFeet\": 4\n",
    "}\n",
    "frequency = 160\n",
    "time_period = 640\n",
    "prc_overlap = .90\n",
    "chunk_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:35:36.742517600Z",
     "start_time": "2024-01-02T18:35:36.612982900Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:35:36.744519100Z",
     "start_time": "2024-01-02T18:35:36.663510200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 made, stores: Samples - (0, 81, 31, 64) | Classes - (0, 0)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(h5Path, \"w\") as specs:\n",
    "    specs.create_dataset(\"Samples\",(0,81,31,64), maxshape=(None,81,31,64),compression=\"gzip\")\n",
    "    specs.create_dataset(\"Classes\",(0,0), maxshape=(None,1), compression=\"gzip\")\n",
    "    print(f\"h5 made, stores: Samples - {specs['Samples'].shape} | Classes - {specs['Classes'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:35:36.744519100Z",
     "start_time": "2024-01-02T18:35:36.697510600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def storeDataSingle(dataSamples, dataLabels, size):\n",
    "    with h5py.File(h5Path, \"r+\") as f:\n",
    "        #Shuffling entries in the chunk\n",
    "        tempLabels = []\n",
    "        tempSamples = []\n",
    "        order = np.random.permutation(np.arange(size))\n",
    "        for pos in order:\n",
    "            tempLabels.append(dataLabels[pos])\n",
    "            tempSamples.append(dataSamples[pos])\n",
    "        \n",
    "        #Updating Samples\n",
    "        df = f['Samples']\n",
    "        current_shape = df.shape\n",
    "        print(f\"Current shape is {df.shape}\")\n",
    "        df.resize((current_shape[0] + size, 81, 31, 64))\n",
    "        df[current_shape[0]:, :] = tempSamples\n",
    "        print(f\"Samples adjusted to {current_shape[0] + size} after adding {size}\")\n",
    "\n",
    "        # Update Lables\n",
    "        labels = f['Classes']\n",
    "        labels.resize((current_shape[0] + size,0))\n",
    "        labels[current_shape[0]:,:] = tempLabels\n",
    "        print(f\"Classes adjusted to {current_shape[0] + size} after adding {size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:40:18.360225200Z",
     "start_time": "2024-01-02T18:35:36.710511200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person 1 completed\n",
      "person 2 completed\n",
      "Current shape is (0, 81, 31, 64)!\n",
      "Samples adjusted to 1000 after adding 1000\n",
      "Classes adjusted to 1000 after adding 1000\n",
      "person 3 completed\n",
      "person 4 completed\n",
      "Current shape is (1000, 81, 31, 64)!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1000,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m samples\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m==\u001b[39m chunk_size:\n\u001b[1;32m---> 52\u001b[0m     \u001b[43mstoreDataSingle\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     labels \u001b[38;5;241m=\u001b[39m samples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     55\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[64], line 16\u001b[0m, in \u001b[0;36mstoreDataSingle\u001b[1;34m(dataSamples, dataLabels, size)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent shape is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m df\u001b[38;5;241m.\u001b[39mresize((current_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m size, \u001b[38;5;241m81\u001b[39m, \u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[1;32m---> 16\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m tempSamples\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSamples adjusted to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_shape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after adding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Update Lables\u001b[39;00m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Humperdink2\\anaconda3\\envs\\nathacks\\lib\\site-packages\\h5py\\_hl\\dataset.py:920\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# If the input data is already an array, let HDF5 do the conversion.\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;66;03m# If it's a list or similar, don't make numpy guess a dtype for it.\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, numpy\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase\n\u001b[1;32m--> 920\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Check for array dtype compatibility and convert\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39msubdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1000,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "#Generating spectograms Images\n",
    "person = 1\n",
    "for folder in os.listdir(dataPath):\n",
    "    for fileName in os.listdir(os.path.join(dataPath,folder)):\n",
    "\n",
    "        #Skipping files .event files\n",
    "        if fileName.find(\"event\") != -1:\n",
    "            continue\n",
    "\n",
    "        #reading EDF file and extracting data\n",
    "        filePath = os.path.join(dataPath,folder,fileName)\n",
    "        annotations = \"\"\n",
    "        file = \"\"\n",
    "\n",
    "        #Getting the annotations and Data\n",
    "        file = pyedflib.EdfReader(filePath)\n",
    "        annotations = file.readAnnotations()\n",
    "        file.close()\n",
    "\n",
    "        signals, signal_headers, header = highlevel.read_edf(filePath)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        #Looping through the various \n",
    "        for i, period in enumerate(annotations[0]):\n",
    "            #Getting signal data for 4 second period\n",
    "            data = signals[:,int(annotations[0][i]):int(annotations[0][i]+time_period)]\n",
    "\n",
    "            f, t, image = signal.spectrogram(data,frequency, nperseg = frequency, noverlap = frequency * prc_overlap)\n",
    "            image = np.transpose(image,(1,2,0))\n",
    "\n",
    "            #Assigning label to file\n",
    "            label = annotations[2][i]\n",
    "\n",
    "            #Categories of the different tests\n",
    "            leftOrRight = [\"03\",\"04\",\"07\",\"08\",\"11\",\"12\"]\n",
    "            if label == \"T1\":\n",
    "                if any(x == fileName[5:7] for x in leftOrRight):\n",
    "                    labels.append(labelsDict[\"leftHand\"])\n",
    "                else: \n",
    "                    labels.append(labelsDict[\"bothHands\"])\n",
    "            elif label == \"T2\":\n",
    "                if any(x == fileName[5:7] for x in leftOrRight):\n",
    "                    labels.append(labelsDict[\"rightHand\"])\n",
    "                else:\n",
    "                    labels.append(labelsDict[\"bothFeet\"])\n",
    "            else:\n",
    "                labels.append(labelsDict[\"rest\"])\n",
    "\n",
    "            samples.append(image)\n",
    "            if len(labels) == chunk_size:\n",
    "                storeDataSingle(samples, labels, chunk_size)\n",
    "                labels = samples = []\n",
    "                \n",
    "            count += 1\n",
    "    print(f\"person {person} completed\")\n",
    "    person +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:40:47.806047900Z",
     "start_time": "2024-01-02T18:40:47.731043600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape is (0, 81, 31, 64)!\n",
      "Samples adjusted to 362 after adding 362\n",
      "Classes adjusted to 362 after adding 362\n"
     ]
    }
   ],
   "source": [
    "storeDataSingle(samples, labels, len(samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nathacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
