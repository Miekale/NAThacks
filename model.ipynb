{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.671132400Z",
     "start_time": "2024-01-02T19:48:48.598131700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "359884eca9a2c9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.770655800Z",
     "start_time": "2024-01-02T19:48:48.613132300Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available(), torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48a1d9d5b76d12ae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.772657100Z",
     "start_time": "2024-01-02T19:48:48.636132700Z"
    }
   },
   "outputs": [],
   "source": [
    "labelsDict = {\n",
    "    \"rest\": 0,\n",
    "    \"leftHand\": 1,\n",
    "    \"rightHand\": 2,\n",
    "    \"bothHands\": 3,\n",
    "    \"bothFeet\": 4\n",
    "}\n",
    "\n",
    "def norm_standardize(data, idx):\n",
    "    mean = np.mean(data, axis=(2, 3))\n",
    "    std = np.std(data, axis=(2, 3))\n",
    "    output =  ((np.transpose(data, axes=(2, 3, 0, 1)) - mean) / std)\n",
    "    \n",
    "    if not std.all():\n",
    "        print(f\"batch that contains stds w/ 0: idx = {idx[0]} to {idx[-1]}\")\n",
    "        print(f\"stds:  {std.shape}\")\n",
    "        print(f\"average of stds: {np.mean(std)}\")\n",
    "        print(f\"data: {data.shape}\")\n",
    "        print(f\"average of data: {np.mean(data)}\")\n",
    "        print(\"========================\")\n",
    "        \n",
    "    return np.transpose(output, axes=(2, 3, 0, 1))\n",
    "    \n",
    "class CustomEEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, h5_dir, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Load h5 file and get class names\n",
    "        self.hf = h5py.File(h5_dir, 'r')\n",
    "        print(\"Opened h5py file\")\n",
    "        print(f'Keys: {[key for key in self.hf.keys()]}')\n",
    "        print(f'Samples shape: {self.hf[\"Samples\"].shape}')\n",
    "        print(f'Classes shape: {self.hf[\"Classes\"].shape}')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hf['Samples'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx is a list [start -> start + batch_size]\n",
    "        # Transpose to channels-first representation for PyTorch\n",
    "        sample = np.transpose(self.hf['Samples'][idx], axes=(0, 3, 1, 2))\n",
    "        \n",
    "        # Feed through transform and return\n",
    "        return self.transform(sample, idx), self.hf['Classes'][idx].argmax(axis=1)\n",
    "    \n",
    "    def size(self):\n",
    "        return self.__len__()\n",
    "            \n",
    "    def close(self):\n",
    "        self.hf.close()\n",
    "        print(\"h5 File Closed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class RandomBatchSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"\n",
    "    Sampling class to create random sequential batches for weak shuffling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_length = len(dataset)\n",
    "        self.n_batches = self.dataset_length / self.batch_size\n",
    "        self.batch_ids = torch.randperm(int(self.n_batches * SIZE)) + int(self.n_batches * THRESH) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # Yield list of indices for that particular batch\n",
    "        for x in self.batch_ids:\n",
    "            idx = torch.arange(x * self.batch_size, (x + 1) * self.batch_size)\n",
    "            for index in idx:\n",
    "                yield int(index)\n",
    "                \n",
    "        # Last batch is smaller than batch_size\n",
    "        if int(self.n_batches) < self.n_batches:\n",
    "            idx = torch.arange(int(self.n_batches) * self.batch_size, self.dataset_length)\n",
    "            for index in idx:\n",
    "                yield int(index)\n",
    "\n",
    "def fast_loader(dataset, batch_size, drop_last=False, transforms=None):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=None,  # None when using samplers\n",
    "        sampler=torch.utils.data.BatchSampler(RandomBatchSampler(dataset, batch_size), batch_size=batch_size, drop_last=drop_last)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.772657100Z",
     "start_time": "2024-01-02T19:48:48.650132Z"
    }
   },
   "id": "e2a5664556e49843"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([86, 82, 89, 80, 83, 87, 81, 85, 84, 88])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(int(100*0.1)) + int(100 * 0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.774657400Z",
     "start_time": "2024-01-02T19:48:48.662132600Z"
    }
   },
   "id": "9dacac9f5f8f3855"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5a04bfaa40a0789",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.774657400Z",
     "start_time": "2024-01-02T19:48:48.684140700Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        # Block 1\n",
    "        self.block1 = nn.Sequential(\n",
    "            # 64 x 81 x 31\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            # nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Block 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            # 64 x 40 x 15 \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            # nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Block 3\n",
    "        self.block3 = nn.Sequential(\n",
    "            # 128 x 20 x 7\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), padding='same'),\n",
    "            # nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Linear\n",
    "        self.linear1 = nn.Flatten()\n",
    "        self.linear2 = nn.Linear(in_features=7680, out_features=100)  \n",
    "        self.linear3 = nn.Linear(in_features=100, out_features=5)  # 5 classes\n",
    "        self.softmax = nn.Softmax()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a14979d2b7a0ceae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.775657100Z",
     "start_time": "2024-01-02T19:48:48.692657800Z"
    }
   },
   "outputs": [],
   "source": [
    "class EEGModel:\n",
    "    def __init__(self, network):\n",
    "        self.model = network\n",
    "        \n",
    "        # Hyper-parameters\n",
    "        self.optimizer = None \n",
    "        self.criterion = None\n",
    "        \n",
    "        # Data\n",
    "        self.dataloaders = dict()\n",
    "        self.dataset_size = dict()\n",
    "    \n",
    "    def set_dataloaders(self, train_loader, val_loader, train_size, val_size):\n",
    "        self.dataloaders['train'] = train_loader\n",
    "        self.dataloaders['val'] = val_loader\n",
    "        self.dataset_size['train'] = train_size\n",
    "        self.dataset_size['val'] = val_size\n",
    "    \n",
    "    def get_trainable_parameters(self):\n",
    "        return self.model.parameters()\n",
    "    \n",
    "    def train_model(self, epochs): \n",
    "        # Send to GPU\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Only stores the weights with best training accuracy\n",
    "        hist = {\n",
    "            'epoch_loss': [],\n",
    "            'epoch_acc': []\n",
    "        }\n",
    "        \n",
    "        # Saves training checkpoints to a temp directory\n",
    "        with TemporaryDirectory() as tempdir:\n",
    "            best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "            torch.save(self.model.state_dict(), best_model_params_path)\n",
    "            \n",
    "            # Looping through epochs\n",
    "            for epoch in range(epochs):\n",
    "                print(f'Epoch {epoch}/{epochs - 1}')\n",
    "                print('-' * 10)\n",
    "\n",
    "                # Each epoch has a training and validation phase\n",
    "                for phase in ['train', 'val']:\n",
    "                    if phase == 'train':\n",
    "                        self.model.train()  \n",
    "                    else:\n",
    "                        self.model.eval()  \n",
    "                        \n",
    "                    running_loss = 0.0\n",
    "                    running_corrects = 0\n",
    "                    \n",
    "                    # Iterate over samples\n",
    "                    s = time.time()\n",
    "                    for inputs, labels in self.dataloaders[phase]:\n",
    "                        # Inputs are batched according to batch size\n",
    "                        shape = inputs.shape\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        \n",
    "                       # Zero grad\n",
    "                        self.optimizer.zero_grad()\n",
    "                    \n",
    "                        # Forward pass\n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = self.model(inputs)\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                            loss = self.criterion(outputs, labels)\n",
    "                            \n",
    "                            # Backwards pass and step optimizer if training phase\n",
    "                            if phase == 'train':\n",
    "                                loss.backward()\n",
    "                                self.optimizer.step()\n",
    "                        \n",
    "                            # Running stats\n",
    "                            running_loss += loss.item() * inputs.size(0)\n",
    "                            running_corrects += torch.sum(preds == labels)\n",
    "                        \n",
    "                    # Epoch stats\n",
    "                    hist['epoch_loss'].append(running_loss / self.dataset_size[phase])\n",
    "                    print(f'Total running corrects: {running_corrects.double()}')\n",
    "                    hist['epoch_acc'].append(running_corrects.double() / (self.dataset_size[phase]))\n",
    "                    \n",
    "                    print(f'Epoch Done after: {time.time() - s}')\n",
    "                    print(f'{phase} Loss: {hist[\"epoch_loss\"][-1]:.4f} Acc: {hist[\"epoch_acc\"][-1]:.6f}')\n",
    "                \n",
    "                # Store weights if this is best so far\n",
    "                if hist['epoch_acc'][-1] > max(hist['epoch_acc']):\n",
    "                    print(\"Model saved!\")\n",
    "                    torch.save(self.model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "            time_elapsed = time.time() - start_time\n",
    "            print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "            print(f'Best Validation Accuracy: {max(hist[\"epoch_acc\"]):4f}')\n",
    "            \n",
    "            # Take the model with best val accuracy\n",
    "            self.model.load_state_dict(torch.load(best_model_params_path))\n",
    "        \n",
    "        # Save model\n",
    "        torch.save(self.model.state_dict(), \"final_model.pt\")\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df88cf2a87d03b71",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.775657100Z",
     "start_time": "2024-01-02T19:48:48.722657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened h5py file\n",
      "Keys: ['Classes', 'Samples']\n",
      "Samples shape: (362, 81, 31, 64)\n",
      "Classes shape: (362, 5)\n",
      "Opened h5py file\n",
      "Keys: ['Classes', 'Samples']\n",
      "Samples shape: (362, 81, 31, 64)\n",
      "Classes shape: (362, 5)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomEEGDataset(\"h5py/1personval2.h5\", transform=norm_standardize)\n",
    "val_dataset = CustomEEGDataset(\"h5py/1persontrain.h5\", transform=norm_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc2b9d2056c894d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.776662300Z",
     "start_time": "2024-01-02T19:48:48.737658800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Debug params just ignore these 2\n",
    "SIZE = 1\n",
    "THRESH = 0\n",
    "\n",
    "# Dataloader object\n",
    "BATCH_SIZE = 8\n",
    "train_loader = fast_loader(train_dataset, BATCH_SIZE)\n",
    "val_loader = fast_loader(val_dataset, BATCH_SIZE)\n",
    "\n",
    "# Train dataloader and validation dataloader combined as a dict\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc1c3abd4a589d6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:48.841176500Z",
     "start_time": "2024-01-02T19:48:48.754659400Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b337a0d053393f8c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:49.407965500Z",
     "start_time": "2024-01-02T19:48:48.785664Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create model object for training\n",
    "model = EEGModel(net)\n",
    "model.set_dataloaders(train_loader, val_loader, train_dataset.size() * SIZE, val_dataset.size() * SIZE)\n",
    "\n",
    "# Hyperparameters\n",
    "WEIGHTS = [1, 1, 1, 1, 1]\n",
    "class_weights = torch.FloatTensor(WEIGHTS).to(device)\n",
    "LR = 0.005\n",
    "MOMENTUM = 0.9\n",
    "CRITERION = nn.CrossEntropyLoss(weight=class_weights)\n",
    "OPTIMIZER = optim.SGD(model.get_trainable_parameters(), LR, 0.9)\n",
    "\n",
    "model.criterion = CRITERION\n",
    "model.optimizer = OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train': 362, 'val': 362}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dataset_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:48:49.437967700Z",
     "start_time": "2024-01-02T19:48:49.409966Z"
    }
   },
   "id": "a16d6db4ea58c25c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f13ac688d5febd4f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T19:49:30.604172900Z",
     "start_time": "2024-01-02T19:48:49.425967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markd\\Documents\\GitHub\\NAThacks\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running corrects: 170.0\n",
      "Epoch Done after: 10.66437840461731\n",
      "train Loss: 1.4577 Acc: 0.469613\n",
      "Total running corrects: 182.0\n",
      "Epoch Done after: 9.904284000396729\n",
      "val Loss: 1.4021 Acc: 0.502762\n",
      "Epoch 1/29\n",
      "----------\n",
      "Total running corrects: 182.0\n",
      "Epoch Done after: 8.424551963806152\n",
      "train Loss: 1.4021 Acc: 0.502762\n",
      "Total running corrects: 182.0\n",
      "Epoch Done after: 8.779491424560547\n",
      "val Loss: 1.4021 Acc: 0.502762\n",
      "Epoch 2/29\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 56\u001B[0m, in \u001B[0;36mEEGModel.train_model\u001B[1;34m(self, epochs)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Iterate over samples\u001B[39;00m\n\u001B[0;32m     55\u001B[0m s \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 56\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloaders[phase]:\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;66;03m# Inputs are batched according to batch size\u001B[39;00m\n\u001B[0;32m     58\u001B[0m     shape \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m     59\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\NAThacks\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\NAThacks\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\NAThacks\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:53\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "Cell \u001B[1;32mIn[12], line 42\u001B[0m, in \u001B[0;36mCustomEEGDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# idx is a list [start -> start + batch_size]\u001B[39;00m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# Transpose to channels-first representation for PyTorch\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m     sample \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSamples\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m, axes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;66;03m# Feed through transform and return\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(sample, idx), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClasses\u001B[39m\u001B[38;5;124m'\u001B[39m][idx]\u001B[38;5;241m.\u001B[39margmax(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mh5py\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\NAThacks\\venv\\lib\\site-packages\\h5py\\_hl\\dataset.py:758\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, args, new_dtype)\u001B[0m\n\u001B[0;32m    756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fast_read_ok \u001B[38;5;129;01mand\u001B[39;00m (new_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    757\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 758\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fast_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    759\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    760\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall back to Python read pathway below\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.train_model(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2aec523876786f0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
